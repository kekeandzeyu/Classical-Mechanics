\section{Lecture 4: Lagrange Multipliers, Near Equilibrium Dynamics \& Oscillators}

\subsection{Lagrange Multipliers: Constrained Optimization}

Our standard Lagrangian approach requires expressing the positions of all particles in terms of generalized coordinates, $r_\alpha\left(q_i, t\right)$. This can be complex making it difficult to obtain an explicit form for the Lagrangian,$L\left(q_i, \dot{q_i}, t\right)$. A natural question arises: can we formulate mechanics directly in terms of the particle positions, $\mathbf{r_\alpha}$, and impose constraints directly at the level of the equations of motion, rather than at the level of the action? This is where Lagrange multipliers become a valuable tool.

\subsubsection{Review of Lagrange Multipliers in Calculus}

Let's first recall how Lagrange multipliers work in standard calculus. Suppose we want to minimize a function $F\left(x, y\right)$. Without constraints, this involves simply finding where the partial derivatives vanish:

\begin{equation}
    \frac{\partial F}{\partial x} = \frac{\partial F}{\partial y} = 0
\end{equation}

However, given by $g\left(x, y\right) = 0$, if we want to minimize $F\left(x, y\right)$ subject to a constraint, we introduce a Lagrange multiplier $\lambda$. We then minimize the modified function: $F\left(x, y\right) + \lambda \ g\left(x, y\right)$. This leads to the following set of equations:

\begin{align}
    \frac{\partial F}{\partial x} + \lambda \ \frac{\partial g}{\partial x} &= 0 \\
    \frac{\partial F}{\partial y} + \lambda \ \frac{\partial g}{\partial y} &= 0 \\
    g\left(x, y\right) &= 0 
\end{align}

Notice that we now have three equations for three unknowns: $x$, $y$, and $\lambda$. The first two equations define the stationary points of $F$ subject to the constraint, and the third equation ensures that the constraint is satisfied. This method provides a systematic way to solve constrained optimization problems.

\subsubsection{Lagrange Multipliers in the Calculus of Variations}

The same principle can be extended to the calculus of variations. Let's say we have $M$ functions $y_i\left(x\right), i = 1, 2, \cdots, M$, and we want to minimize an action integral:

\begin{equation}
    I[y_i\left(x\right)] = \int dx \ F\left(y_i, \dot{y_i}, x\right)
\end{equation}

Furthermore, suppose we have $M-N$ constraints of the form $G_k[y_i] = 0, k = 1, 2, \cdots, M - N$. The traditional approach would be to express all $M$ functions, $y_i$, in terms of $N$ independent degrees of freedom, however, we can avoid this by using Lagrange multipliers. To incorporate the constraints, we modify the action integral as follows:

\begin{equation}
    \tilde{I}[y_i, \lambda_k] = \int dx \ \left(F\left(y_i, \dot{y_i}, x\right) + \sum_k \lambda_k \left(x\right) G_k[y_i]\right)
\end{equation}

Here, $\lambda_k(x)$ are now functions of $x$, the independent variable of the integral. 
We treat $\tilde{I}$ as the functional we want to minimize, and obtain its Euler-Lagrange equations:

\begin{align}
    \frac{\delta \tilde{I}}{\delta y_i}  = \frac{\delta I}{\delta y_i} + \sum_k \lambda_k \frac{\delta G_k}{\delta y_i} &= 0 \\
    G_k[y_i] &= 0
\end{align}

This gives us a total of $M + (M - N)$ equations. We have $M$ equations from the functional derivative with respect to each $y_i$, plus $M-N$ equations from the constraints. These equations involve the $M$ unknowns  $y_i$ and the $M-N$ Lagrange multiplier functions, $\lambda_k(x)$. These can, in principle, be solved to obtain the solution to the constrained variational problem.

\begin{example}
    Compute the equations of motion in \ref{ex:2-1} again, but this time using Lagrange multipliers.
\end{example}

Now we treat $x$ \& $y$ as independent variables, and they subject to $x^2+y^2-l^2=0$.
    
\begin{equation}
    G\left(x, y\right) = x^2 + y^2 - l^2
\end{equation}

\begin{equation}
    L = \frac{1}{2} m \left(\dot{x} ^ 2 + \dot{y} ^ 2\right) - mgy
\end{equation}

\begin{equation}
    L + \lambda G = \frac{1}{2} m \left(\dot{x} ^ 2 + \dot{y} ^ 2\right) - mgy + \lambda \left(x^2 + y^2 - l^2\right)
\end{equation}

So by taking the derivative of $L + \lambda G$ with respect to $x$, we can get:

\begin{align}
    \label{eq:4-12}
    m \ddot{x} - 2 \lambda x &= 0 \\
    \label{eq:4-13}
    m \ddot{y} + mg - 2 \lambda y &= 0 \\
    x ^ 2 + y ^ 2 &= l ^ 2
\end{align}

From \ref{eq:4-12} and \ref{eq:4-13} we get:

\begin{equation}
    m \frac{\ddot{x}}{x} = m \left(\frac{\ddot{x}}{x} + \frac{g}{y}\right)
\end{equation}

\begin{equation}
    \label{eq:4-16}
    \ddot{x} y - \ddot{y} x - gx = 0
\end{equation}

Previously from \ref{eq:2-12} and \ref{eq:2-13} we get the time derivatives of the coordinates are:

\begin{align}
    \dot{x} &= l \cos{\theta} \cdot \dot{\theta} \\
    \dot{y} &= l \sin{\theta} \cdot \dot{\theta} 
\end{align}

So the second time derivatives of the coordinates are:

\begin{align}
    \label{eq:4-19}
    \ddot{x} &= l\left(\cos \theta \ \ddot{\theta} - \sin \theta \ \dot{\theta}^2\right) \\
    \label{eq:4-20}
    \ddot{y} &= l\left(\sin \theta \ \ddot{\theta} + \cos \theta \ \dot{\theta}^2\right)
\end{align}

Take \ref{eq:4-19} and \ref{eq:4-20} into \ref{eq:4-16}, we can get:

\begin{equation}
    \ddot{\theta} = -\frac{g}{l} \sin \theta
\end{equation}

This is the same as what we got in \ref{eq:2-18}.

\subsection{Oscillators}

So far we have written down equations of motion. Now we will solve them for a simple oscillator. Consider a general 1D system, where the degree of freedom is $q$ and the langrangian is $L\left(q, \dot{q}\right)$. An equilibrium solution is one where $q = \text{const} = q_0$, and $q$ is independent of time.

The equation of motion:

\begin{equation}
    \frac{d}{dt} \left(\frac{\partial L}{\partial \dot{q}}\right) - \frac{\partial L}{\partial q} = 0
\end{equation}

is a $2^\text{nd}$ order differential equation. Solutions depend on initial values of $q$, $\dot{q}$ at the same time $t$.

For an equilibrium solution, $q = q_0$, $\dot{q} = 0$ will remain at rest only if $\ddot{q} = 0$.

\begin{equation}
    L = T - V \rightarrow 0 = - \frac{d}{dt} \left(\frac{\partial T}{\partial \dot{q}}\right) + \frac{\partial T}{\partial q} + \frac{\partial V}{\partial q}
\end{equation}

This vanishes when $\frac{\partial V}{\partial q} \big |_{q_0} = 0$.

There are two types of equilibrium solutions, namely stable equilibrium and unstable equilibrium. Consider a small perterbation around an equilibrium point $q=q_0=0$, let's expand around the equilibrium point:

\begin{equation}
    L = A + Bq + C\dot{q} + Dq^2 + E\dot{q}^2 + Fq\dot{q} + \cdots
\end{equation}

The EOM will remain unchanged if you add total time derivative to $L$:

\begin{equation}
    L \rightarrow L + \frac{d}{dt} J 
\end{equation}

\begin{equation}
    S \rightarrow S + \sum_{t_0}^{t_1} dt \ \frac{d}{dt} J = S + J\left(t_1\right) - J\left(t_0\right)
\end{equation}

I can ignore $A$, $C$ and $E$, so we can get:

\begin{equation}
    \frac{\partial V}{\partial q} = 0 \rightarrow B = 0
\end{equation}

\begin{equation}
    L = F \dot{q} + D q^2 = 2F \left(\frac{1}{2} \dot{q}^2 + \frac{D}{2F} q^2\right)
\end{equation}

This is equivalent to 

\begin{equation}
    L = \frac{1}{2} \left(\dot{q}^2 + \frac{D}{F} q^2\right)
\end{equation}

Let the frequency $\omega$ be:

\begin{equation}
    \omega^2 = - \frac{D}{F}
\end{equation}

So the equations of motion are: 

\begin{equation}
    \ddot{q} - \frac{D}{F} q = 0
\end{equation}

which is,

\begin{equation}
    \ddot{q} + \omega^2 q = 0
\end{equation}

If $\omega$ is real ($\frac{D}{F} > 0$), then the solutions to the equations of motion are:

\begin{equation}
    q = A \sin{\omega t} + B \cos{\omega t}
\end{equation}  

The solution oscillates around $q = 0$ with frequency $\omega$. In this case the equilibrium is stable.

If the $\omega$ is imaginary ($\frac{D}{F} < 0$), then we can get:

\begin{equation}
    q = A e^{i \omega t} + B e^{-i \omega t}
\end{equation}

generically (unless we choose initial condition with $A = 0$) the perterbation grows in time. The equilibrium is then unstable.